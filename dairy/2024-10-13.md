※10月13日以前に学習した内容もついでにまとめてます。

:open_book:教材：[駆け出しエンジニアのためのDocker入門](https://www.udemy.com/course/docker-startup/?couponCode=PLOYALTY0923)

- なぜDockerが必要か？
   - 環境構築時間の削減  
　今までは環境構築するとなると
     - webサーバーをインストール
     - 使用する言語をインストール
     - DBをインストール
     - 初期設定をする
     - ユーザーやネットワークを作る…  
といった作業が必要だった。  
Dockerでは
     - 設計図を作る
     - `docker compose build, docker compose up`  
のみで環境構築が行える。  
Dockerは設計図通りに環境構築をするだけなので、設計図が間違っていなければ、同じ設計図から必ず同じコンテナが作られる。  
これまでの環境構築は人の手で行われていたので、ミスが起きるなどの問題が起きてしまっていた。  
   - アプリ実行環境の品質UP  
開発言語やWebサーバーのバージョンと実際にインターネット上に公開しているサーバーは微妙に違う。  
そのため、同じようなものをインストールして同じようなものを作ろうと努力しても、それができない場合もある（！）  
Dockerを使うと、同じ設計図をいろいろな環境で使いまわすことができるため、Dockerの設計図があれば、OS、PCスペック、サーバーのスペックやOSは関係なくなる。  
DockerがハードウェアやOSの差異を吸収してくれるので、アプリ開発の環境の品質が上がり、環境依存のエラーが起こらなくなる。  
   - 自動化ソフトとの相性  
Dockerを使うと、テストや本番環境へのファイルのコンパイルやデプロイ（本番環境へのデータのアップロード）の自動化（[CI/CDパイプライン](https://www.ashisuto.co.jp/devops-portal/cat05/cicd.html)）がききやすくなる。  
[Jenkins](https://e-words.jp/w/Jenkins.html)や[CircleCI](https://freelance.shiftinc.jp/column/circleci)というCI/CDツールが有名。  
これらのツールを使うことで、人がやっていた面倒な作業を自動化できる。

- コンテナについて  
  Dockerはコンテナを管理するためのツール  
  - そもそもコンテナって？  
  サーバー上に隔離されたアプリ空間を作れる技術のこと。  
  サーバーの中にパッケージ化されたソフトがいくつもならぶような構造をつくれるのがコンテナ。  
  基本的に1コンテナに1ソフト
- 仮想環境とDockerの違い  
  - 仮想環境
  仮想環境はパソコンの中にパソコンを作る技術。元のパソコンがホストOS、パソコンのなかに作ったパソコンがゲストOS。  
  隔離された環境を作るために必要だった。  
  本番環境をインターネット上に公開するサーバーはほぼLINUXなので、Windowsで開発してLINUXに持っていくと、環境の違いから思わぬ不具合につながったり、そもそもWindowsだとサーバーが建てられなかったりした。  
  VirtualBoxなどのソフトを使ってWindowsのなかにLINUXのサーバーを建てることで、WindowsでもLINUXのアプリ開発ができるようになる。  
  クラウド上の大きなサーバーを複数に分割するような使い方をするときは、小さなサーバーをいくつか立ち上げて仮想環境を使って区切りをつけていた。  

|  | Docker | 仮想環境 |
| ---- | ---- | ---- |
| 存在場所 | メモリ上 | ディスク上 |
| ゲストOS | 存在しない | ホストOSとゲストOSに分かれる |
| データ管理 | 一時保存 | 常に保存 |
| コード化 | Dockerfileで可能 | 不可 |

DockerはLINUXサーバー上に直接各ソフトウェアのコンテナが立ち上がるイメージ。
メモリ上にいるので、アプリを開いているような感覚。
また、インフラがコード化できるので、インフラの構成はファイルを見れば一発で理解できる。
仮想環境はデータがディスクにあるので、常にデータが保存されている。


- インフラのコード化  
  サーバーは最初はまっさらで、ここで`sudo install php`のような直接ソフトをインストールしていくコマンドを打っていくのがインフラ構築だった。  
  しかし、これでは書いたコードをメモしておくくらいでしかインフラの状況を把握できなかった。  
  そのため、常に一定のサーバーの状態のものをいくつも作るのは難しかった。  
  これを、***Dockerfile***という技術で、手動で作っていたサーバーをすべてコード化して定義することができるようになった。  
  Dockerfileがインフラの設計図になり、同じ設計図からは必ず同じコンテナが生成されるので、同じ設計図を使えば誰もが同じサーバーを作れるようになった。
  しかも、コードだからテキストファイルであるため、受け渡しも簡単に行える。
  これがDockerを使用する大きなメリット。
  Dockerfileにはサーバーで実行するコードが定義されていて、設定を自動で行ってくれる。
  であるため、設計図が同じなら必ず同じサーバーになる。  
  インフラの知識のないエンジニアでも簡単にサーバーが立てられるため、時短にもなる。  
  また、人の手が介在しないため、必ず同じものができることから、そもそもミスが起こらなかったり、ちょっとしたサーバートラブルにも対応しやすい。  
  インフラをコードで定義してコード化することを  
  ***Infrastructure As a Code***  
  という。
